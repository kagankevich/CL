{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "kagankevich - hw2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JdJ7kkEI4LC2"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kagankevich/CL/blob/master/kagankevich_hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl9yd-oRijTa",
        "colab_type": "text"
      },
      "source": [
        "# Большая домашка 1: классификация отзывов\n",
        "\n",
        "## Данные\n",
        "\n",
        "Скачиваются по [ссылке](https://drive.google.com/open?id=1gJEpwM3zdV5xe9nRU0VwQmGTiOTQdp10). Это отзывы пользователей на фильмы с КиноПоиска."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AosN25b-ijTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3JRHsALijTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('reviews.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5860IX05ijTo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "23636916-bf3d-445a-9b4a-f38934c5ba68"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Эпиграф Добро которое ты делаешь от сердца ты ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Теперь это один из моих любимых фильмов в жанр...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Что скрыто в фильме Лучше не бывает Одна шикар...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Перед нами очень милое и доброе кино которое л...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Завязка Мелвин Удал популярный писатель Нет не...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0      1  Эпиграф Добро которое ты делаешь от сердца ты ...\n",
              "1      1  Теперь это один из моих любимых фильмов в жанр...\n",
              "2      1  Что скрыто в фильме Лучше не бывает Одна шикар...\n",
              "3      1  Перед нами очень милое и доброе кино которое л...\n",
              "4      1  Завязка Мелвин Удал популярный писатель Нет не..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae-5qGUAijTv",
        "colab_type": "code",
        "outputId": "4012b2ba-b752-4419-de48-851a71d50383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "set(df.label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{-1, 0, 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VScQ6EhbijT4",
        "colab_type": "text"
      },
      "source": [
        "В колонке `label` три класса: положительный (1), нейтральный (0) и отрицательный (-1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3SetQOYijT5",
        "colab_type": "text"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50ht46wLijT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe1nO9vkzMLD",
        "colab_type": "code",
        "outputId": "7cfeb830-c372-4738-c197-e07363ac1fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "!pip install pymorphy2[fast]\n",
        "import pymorphy2\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from operator import itemgetter\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2[fast]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\r\u001b[K     |███████                         | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Collecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 6.1MB/s \n",
            "\u001b[?25hCollecting DAWG>=0.7.3; extra == \"fast\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/ef/91b619a399685f7a0a95a03628006ba814d96293bbbbed234ee66fbdefd9/DAWG-0.8.0.tar.gz (371kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 45.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: DAWG\n",
            "  Building wheel for DAWG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for DAWG: filename=DAWG-0.8.0-cp36-cp36m-linux_x86_64.whl size=842398 sha256=6786dad9a083e94e25b3371584e8b23aa01613e491a5356079df28fabdd6bb04\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/1f/f0/a5b1f9d02e193c997d252c33d215f24dfd7a448bc0166b2a12\n",
            "Successfully built DAWG\n",
            "Installing collected packages: dawg-python, pymorphy2-dicts, DAWG, pymorphy2\n",
            "Successfully installed DAWG-0.8.0 dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk-xJ7DQijUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vec = CountVectorizer()\n",
        "bag_of_words = vec.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, df.label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT6VTRA8ijUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb = MultinomialNB()\n",
        "clf = nb.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRm_3gEPijUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJt1EMzcijUV",
        "colab_type": "code",
        "outputId": "a06c7a1e-ed6e-4dc2-e888-6a74612ac57f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "print(classification_report(y_test, clf.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.69      0.23      0.34      1058\n",
            "           0       0.37      0.08      0.13      1390\n",
            "           1       0.82      0.98      0.89      9178\n",
            "\n",
            "    accuracy                           0.81     11626\n",
            "   macro avg       0.63      0.43      0.46     11626\n",
            "weighted avg       0.76      0.81      0.75     11626\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZxc0L8GijUa",
        "colab_type": "text"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Побейте baseline выше как минимум тремя способами.\n",
        "\n",
        "\n",
        "**Обязательно**:\n",
        "* попробовать разный препроцессинг (2 балла)\n",
        "* попробовать разные классификаторы (2 балла)\n",
        "* поподбирать гиперпараметры классификаторов, можно с использованием GreedSearch (2 балла)\n",
        "* попробуйте объяснить полученные результаты (2 балла)\n",
        "* визуализируйте веса признаков для лучшей модели (если лучшая модель не выдаёт коэффициенты признаков, возьмите логистическую регрессию); какие признаки оказались самыми значимыми? (2 балла)\n",
        "\n",
        "Если вы перебрали уже много разных способов и выполнили все обязательные критерии, но побить baseline тремя способами так и не получилось, не беспокойтесь. Главное -- полнота попыток :)\n",
        "\n",
        "Good luck and have fun! ;)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhyholQKplHY",
        "colab_type": "code",
        "outputId": "4e9614e5-ac4c-49a8-b080-c6ca5e518885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# видим, что текст уже без знаков препинания\n",
        "df.iloc[10].text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Казалось бы жизнь интроверта Мелвилла Юделла ничем не примечательна живет один ненавидит людей пишет книги и т п Он не пользовался популярностью и симпатией у соседей у окружающий людей из-за своей мизантропической натуры однако с появлением маленького друга который прервал его одиночество Мелвилл стал меняться к лучшему История фильма не особо оригинальная ибо рассказы про мизантропов и замкнутых людей есть чуть ли не в каждой психологической драме но раскрывается она не так сполна как в этой ленте Казалось бы этот мужчина проживет всю жизнь в скукоте и ненависти но с появлением маленького песика Верделла к которому он привязался открыв для себя новые чувства и со временем поняв что жизнь за пределами одиночества полна красок Выбравшись из душевного заточения наш герой ближе знакомится со своим соседом-геем который остался инвалидом после несчастного случая и с официанткой которая хочет вылечить тяжело больного сына и рассеивает все их комплексы и проблемы излечив их путем добра и любви Фильм очень добрый и светлый не зацикливается на темных моментах но имеет жизненный и глубокий смысл и думаю каждый сможет вынести для себя урок после приятного просмотра этой картины Сценарий написан хорошо так как зритель с интересом на одном дыхании наблюдает за происходящим и порадовало еще то что фильм полон качественного и остроумного юмора который легко граничит между светлыми шутками и толерантным стебом который не лишен смысла Конечно же в основном заслуга хорошей у репутации благодаря прекрасному актерскому составу который своим присутствием и игрой справил на нас отличное впечатления Культовый и безумный Джек Николсон идеально смотрится в роли замкнутого и циничного хейтера который несмотря на все грязные выходки чем-то симпатизирует однако со временем все добро и любовь таившаяся в его душе начинает выходить наружу медленно обращая его в неравнодушного доброго отзывчивого и романтического человека как герои его книг Сняв темные очки наш герой посмотрел на жизнь со светлой стороны и решил помочь несчастным людям излечив их от душевных невзгод Компанию нашему красавцу составила Хелен Хант которая сыграла неординарную буйную и самокритичную женщину которая несмотря на это была чистосердечной и доброй которой не хватало отношений в жизни и художник-гей Грег Киннер который после инцидента стал инвалидом брошенным всеми Эти герои смотрелись очень реалистично в данных образах ты с ними переживаешь и с ними радуешься уж больно сильно они цепляют за душу своей харизмой и талантом Также выделю Джилл маленькую и лохматую собачонку совершенно неприметную и неотесанную однако благодаря ей все наши герои получили душевную радость и удовлетворение от жизни Известный всеми Ханс Циммер подарил данному шедевру прекрасную и душевную музыку которая еще больше дополняют атмосферу яркими и приятными красками Итог Достаточно светлый и добрый жизненный фильм который порадует интересной историей со смыслом прекрасными актерами ну и конечно же легким и приятным юмором Если вы уважающий себя киноман и любитель душевного кино то этот фильм создан для вас лучше фильма не бывает из Помните - все к лучшему из из из'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdJ7kkEI4LC2",
        "colab_type": "text"
      },
      "source": [
        "## Tfidf + Naive Bayes без препроцессинга"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRvoPv2w1vfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tfidf без препроцессинга\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b9rgSmJ2MiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_vecs = vectorizer.fit_transform(df.text)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA-SMhDTOngk",
        "colab_type": "code",
        "outputId": "a4e83310-0f11-4390-b8f6-4d873821ea8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "tfidf_vecs"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<46501x369844 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 11693675 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbcHx3XhIKBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_vecs, df.label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxMjeqtlO22b",
        "colab_type": "code",
        "outputId": "55a84ee8-a0ba-477d-fa07-bf626a97a367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nb_tfidf = MultinomialNB() \n",
        "nb_tfidf.fit(X_train, y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0reCULtE3rXn",
        "colab_type": "code",
        "outputId": "b7dcc8e5-a3cc-469c-85a8-1e26cd20d0ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(classification_report(y_test, nb_tfidf.predict(X_test)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00      1079\n",
            "           0       0.00      0.00      0.00      1410\n",
            "           1       0.79      1.00      0.88      9137\n",
            "\n",
            "    accuracy                           0.79     11626\n",
            "   macro avg       0.26      0.33      0.29     11626\n",
            "weighted avg       0.62      0.79      0.69     11626\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9s2zPAOPDDK",
        "colab_type": "text"
      },
      "source": [
        "**Классификатор сработал только по одному классу - в чем может быть проблема?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGgOJ6TGS_-K",
        "colab_type": "text"
      },
      "source": [
        "## CountVectorizer + Logistic Regression без препроцессинга"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ESV68IFTFD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocCpZzYsxeN0",
        "colab_type": "code",
        "outputId": "e6927f40-d46c-4283-b383-ef8924887c62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "bow = vectorizer.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bow, df.label)\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdJP79eMxvkJ",
        "colab_type": "code",
        "outputId": "e087eff9-f68a-4ba9-909f-14ca886f36c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "print(classification_report(y_test, clf.predict(X_test))) # лучше, чем baseline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.61      0.53      0.57      1075\n",
            "           0       0.35      0.28      0.31      1380\n",
            "           1       0.89      0.94      0.91      9171\n",
            "\n",
            "    accuracy                           0.82     11626\n",
            "   macro avg       0.62      0.58      0.60     11626\n",
            "weighted avg       0.80      0.82      0.81     11626\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_bBNsHTZ_DF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrfCr-WIyrRY",
        "colab_type": "text"
      },
      "source": [
        "## Tfidf Vectorizer + Logistic Regression без препроцессинга"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF1nt6kpy3fd",
        "colab_type": "code",
        "outputId": "23c97034-3280-4e91-a7a7-4fea56345bce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "bow = vectorizer.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bow, df.label)\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CutSwF0lzXgN",
        "colab_type": "code",
        "outputId": "b68ce927-f680-45b3-fc0a-dba6827af4ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "print(classification_report(y_test, clf.predict(X_test))) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.73      0.40      0.52      1125\n",
            "           0       0.49      0.12      0.19      1397\n",
            "           1       0.84      0.99      0.91      9104\n",
            "\n",
            "    accuracy                           0.83     11626\n",
            "   macro avg       0.69      0.50      0.54     11626\n",
            "weighted avg       0.79      0.83      0.79     11626\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w2bJT-t0PsU",
        "colab_type": "text"
      },
      "source": [
        "Результат лучше, чем baseline, и примерно такой же, как в CountVectorizer + Logistic Regression без препроцессинга. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zojM4BEhSE9V"
      },
      "source": [
        "## Препроцессинг"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVuEPAg2W4hh",
        "colab_type": "text"
      },
      "source": [
        "### 1. попробуем просто разбить на биграммы и классифицировать baseline-способом\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uupn9IGnijUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vec_bigrams = CountVectorizer(ngram_range=(2, 2)) #  делаем биграммы\n",
        "bow_bigrams = vec_bigrams.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bow_bigrams, df.label)\n",
        "nb = MultinomialNB()\n",
        "clf = nb.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URvB6Ag2SnFN",
        "colab_type": "code",
        "outputId": "e868afae-1c09-40c1-d38e-c56a7959c64d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "print(classification_report(y_test, clf.predict(X_test))) # результаты ухудшились"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.49      0.06      0.11      1090\n",
            "           0       0.18      0.07      0.10      1428\n",
            "           1       0.79      0.96      0.87      9108\n",
            "\n",
            "    accuracy                           0.76     11626\n",
            "   macro avg       0.49      0.36      0.36     11626\n",
            "weighted avg       0.69      0.76      0.70     11626\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATc5NT6zW-dt",
        "colab_type": "text"
      },
      "source": [
        "### 2. попробуем лемматизировать с помощью Pymorphy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gofe8HyJDEC",
        "colab_type": "code",
        "outputId": "2643be95-eb40-4043-cab1-b75f9474e091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "#nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puykIpBqbxrT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8G2xAj5tEGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "morph_analyzer = pymorphy2.MorphAnalyzer()\n",
        "#russian_stopwords = stopwords.words('russian')\n",
        "\n",
        "# функция для лемматизации\n",
        "def preprocess_lemmatize(text):\n",
        "    \n",
        "    text_preprocessed_tokenized = []\n",
        "        \n",
        "    clean_words = [word for word in word_tokenize(text) if word]\n",
        "    clean_words = [word.lower() for word in clean_words if word]\n",
        " #   clean_words = [word for word in clean_words if word not in russian_stopwords]\n",
        "        \n",
        "    clean_lemmas = [morph_analyzer.parse(word)[0].normal_form for word in clean_words]\n",
        "        \n",
        "    text_preprocessed_tokenized.extend(clean_lemmas)\n",
        "\n",
        "    return text_preprocessed_tokenized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMAw35hBEhNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# для лемм используем TfidfVectorizer\n",
        "\n",
        "lemmas_vectorizer = TfidfVectorizer(tokenizer=preprocess_lemmatize)\n",
        "lemmas_bow = lemmas_vectorizer.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(lemmas_bow, df.label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcUUtaJvb1XR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f520fa41-7e74-455e-8cc2-e74f71eb4243"
      },
      "source": [
        "clf = LogisticRegression()\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeQH_ZHJJYOi",
        "colab_type": "code",
        "outputId": "b9920601-dc0e-4b5c-f0ea-64789233764f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "print(classification_report(y_test, clf.predict(X_test))) # самый лучший результат пока"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.73      0.49      0.59      1079\n",
            "           0       0.49      0.17      0.25      1382\n",
            "           1       0.86      0.98      0.92      9165\n",
            "\n",
            "    accuracy                           0.84     11626\n",
            "   macro avg       0.70      0.55      0.59     11626\n",
            "weighted avg       0.81      0.84      0.81     11626\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gANZXxDSghac",
        "colab_type": "text"
      },
      "source": [
        "**Результаты после лемматизации**\n",
        "\n",
        "**Tfidf vectorizer**\n",
        "              \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          -1       0.74      0.50      0.60      1121\n",
        "           0       0.45      0.15      0.22      1388\n",
        "           1       0.86      0.98      0.92      9117\n",
        "\n",
        "    accuracy                           0.84     11626\n",
        "    macro avg       0.68      0.54      0.58     11626\n",
        "    weighted avg       0.80      0.84      0.80     11626\n",
        "\n",
        "**Count Vectorizer**\n",
        "              \n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "          -1       0.65      0.55      0.60      1092\n",
        "           0       0.38      0.29      0.33      1355\n",
        "           1       0.90      0.94      0.92      9179\n",
        "\n",
        "    accuracy                           0.83     11626\n",
        "    macro avg       0.64      0.59      0.61     11626\n",
        "    weighted avg       0.81      0.83      0.82     11626"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFnvwZ__XE9v",
        "colab_type": "text"
      },
      "source": [
        "### анализ результатов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8na6Xj65NLoW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6cdf999c-278c-4d3d-c0db-2e011a2dec25"
      },
      "source": [
        "# print features here\n",
        "lemmas_vectorizer.vocabulary_"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'эпиграф': 143546,\n",
              " 'добро': 31315,\n",
              " 'который': 52321,\n",
              " 'ты': 126646,\n",
              " 'делать': 28454,\n",
              " 'от': 80847,\n",
              " 'сердце': 111469,\n",
              " 'всегда': 19195,\n",
              " 'себя': 110722,\n",
              " 'литр': 56907,\n",
              " 'наш': 69777,\n",
              " 'толстой': 124255,\n",
              " 'думать': 33494,\n",
              " 'я': 144546,\n",
              " 'не': 69853,\n",
              " 'погрешить': 89091,\n",
              " 'против': 99463,\n",
              " 'истина': 43694,\n",
              " 'если': 34791,\n",
              " 'сказать': 112650,\n",
              " 'что': 139038,\n",
              " 'хороший': 135921,\n",
              " 'в': 13793,\n",
              " 'это': 144010,\n",
              " 'фильм': 131794,\n",
              " '-': 0,\n",
              " 'собачка': 115079,\n",
              " 'оскар': 80323,\n",
              " 'она': 79275,\n",
              " 'прекрасный': 95664,\n",
              " 'оригинальный': 80018,\n",
              " 'и': 40666,\n",
              " 'достигнуть': 32428,\n",
              " 'такой': 122076,\n",
              " 'вершина': 15307,\n",
              " 'актёрский': 2977,\n",
              " 'мастерство': 60894,\n",
              " 'к': 44248,\n",
              " 'смочь': 114672,\n",
              " 'дотянуться': 32526,\n",
              " 'даже': 26840,\n",
              " 'джек': 29719,\n",
              " 'николсон': 74773,\n",
              " 'а': 1363,\n",
              " 'как': 44593,\n",
              " 'мы': 66591,\n",
              " 'весь': 15421,\n",
              " 'известно': 41215,\n",
              " 'план': 87461,\n",
              " 'ещё': 34878,\n",
              " 'тот': 124720,\n",
              " 'красавчик': 52732,\n",
              " 'вдруг': 14648,\n",
              " 'вы': 19963,\n",
              " 'на': 67138,\n",
              " 'минутка': 63593,\n",
              " 'прийти': 96615,\n",
              " 'голова': 24404,\n",
              " 'слишком': 113936,\n",
              " 'быстро': 13298,\n",
              " 'ворчливый': 18361,\n",
              " 'писатель': 87156,\n",
              " 'растаять': 103863,\n",
              " 'просто': 99282,\n",
              " 'заглянуть': 36697,\n",
              " 'бездонный': 7928,\n",
              " 'глаз': 23724,\n",
              " 'воистину': 17776,\n",
              " 'двигатель': 27386,\n",
              " 'добрый': 31383,\n",
              " 'дело': 28510,\n",
              " 'прогресс': 98135,\n",
              " 'ментальный': 62209,\n",
              " 'рост': 107180,\n",
              " 'тут': 126556,\n",
              " 'же': 35115,\n",
              " 'мочь': 65572,\n",
              " 'удержаться': 127749,\n",
              " 'аллюзия': 3311,\n",
              " 'сияние': 112615,\n",
              " 'иначе': 42207,\n",
              " 'торренс': 124665,\n",
              " 'выжить': 20286,\n",
              " 'вселиться': 19262,\n",
              " 'чтобы': 139064,\n",
              " 'наконец': 68133,\n",
              " 'превратиться': 95122,\n",
              " 'мелвин': 61949,\n",
              " 'адел': 2248,\n",
              " 'топор': 124523,\n",
              " 'вот': 18667,\n",
              " 'только': 124307,\n",
              " 'потерять': 94100,\n",
              " 'то': 124038,\n",
              " 'прийтись': 96617,\n",
              " 'учиться': 130248,\n",
              " 'запирать': 38103,\n",
              " 'дверь': 27378,\n",
              " 'по': 87985,\n",
              " 'пять': 101370,\n",
              " 'раз': 101781,\n",
              " 'защититься': 39273,\n",
              " 'назойливый': 67840,\n",
              " 'сосед': 116251,\n",
              " 'иногда': 42494,\n",
              " 'тяжело': 126935,\n",
              " 'житься': 35910,\n",
              " 'человек': 137864,\n",
              " 'иметь': 42054,\n",
              " 'окр': 78836,\n",
              " 'обсессивно-компульсивный': 77227,\n",
              " 'расстройство': 103794,\n",
              " 'безлико': 8009,\n",
              " 'назвать': 67806,\n",
              " 'навязчивый': 67412,\n",
              " 'состояние': 116370,\n",
              " 'хорошо': 135937,\n",
              " 'у': 127064,\n",
              " 'фиксация': 131605,\n",
              " 'цифра': 137388,\n",
              " 'например': 68655,\n",
              " 'бы': 13195,\n",
              " 'стоялый': 119020,\n",
              " 'бедняга': 7703,\n",
              " 'час': 137648,\n",
              " 'ключ': 49265,\n",
              " 'замок': 37771,\n",
              " 'крутило': 53685,\n",
              " 'с': 108181,\n",
              " 'счёт': 121186,\n",
              " 'сбиться': 109633,\n",
              " 'ой-вэй': 78579,\n",
              " 'серьёзно': 111668,\n",
              " 'симпатичный': 112189,\n",
              " 'простота': 99323,\n",
              " 'искренность': 43314,\n",
              " 'призвать': 96535,\n",
              " 'достучаться': 32478,\n",
              " 'до': 31237,\n",
              " 'недоверчивый': 70727,\n",
              " 'скептик': 112963,\n",
              " 'вполне': 18837,\n",
              " 'справедливо': 117393,\n",
              " 'заметить': 37707,\n",
              " 'как-то': 44616,\n",
              " 'уж': 127907,\n",
              " 'меняться': 62258,\n",
              " 'возраст': 17716,\n",
              " 'причём': 97705,\n",
              " 'никакой': 74704,\n",
              " 'глобальный': 23853,\n",
              " 'катарсис': 46122,\n",
              " 'быть': 13347,\n",
              " 'причина': 97666,\n",
              " 'происходить': 98490,\n",
              " 'очевидно': 82777,\n",
              " 'он': 79246,\n",
              " 'большой': 11132,\n",
              " 'лохматый': 57549,\n",
              " 'пёс': 101399,\n",
              " 'громко': 25879,\n",
              " 'басовито': 7352,\n",
              " 'лаять': 55606,\n",
              " 'но': 75086,\n",
              " 'кусаться': 54592,\n",
              " 'самый': 109095,\n",
              " 'уметь': 128694,\n",
              " 'перед': 85112,\n",
              " 'настырный': 69305,\n",
              " 'так': 121979,\n",
              " 'вообще': 18155,\n",
              " 'пасовать': 84037,\n",
              " 'почти': 94594,\n",
              " 'сразу': 117545,\n",
              " 'всячески': 19617,\n",
              " 'пытаться': 101086,\n",
              " 'удержать': 127748,\n",
              " 'дальний': 26959,\n",
              " 'дистанция': 31060,\n",
              " 'для': 31189,\n",
              " 'самозащита': 108723,\n",
              " 'понимать': 92514,\n",
              " 'ближний': 10234,\n",
              " 'ничто': 75025,\n",
              " 'они': 79317,\n",
              " 'сделать': 110644,\n",
              " 'уже': 127959,\n",
              " 'действительно': 28330,\n",
              " 'разглядеть': 102103,\n",
              " 'куда': 54038,\n",
              " 'потом': 94138,\n",
              " 'деваться': 27703,\n",
              " 'также': 122037,\n",
              " 'длинный': 31173,\n",
              " 'перечень': 86090,\n",
              " 'всевозможный': 19186,\n",
              " 'нетолерантность': 73974,\n",
              " 'персонаж': 86269,\n",
              " 'столько': 118879,\n",
              " 'жизненный': 35747,\n",
              " 'позиция': 90630,\n",
              " 'сколько': 113121,\n",
              " 'поиск': 90706,\n",
              " 'другой': 33212,\n",
              " 'недостаток': 70991,\n",
              " 'несовместимый': 73709,\n",
              " 'жизнь': 35794,\n",
              " 'получить': 92087,\n",
              " 'адекватный': 2247,\n",
              " 'оградить': 77908,\n",
              " 'да': 26714,\n",
              " 'попадаться': 92742,\n",
              " 'герой': 22823,\n",
              " 'шутка': 141397,\n",
              " 'женщина': 35328,\n",
              " 'голубой': 24502,\n",
              " 'еврей': 34327,\n",
              " 'собака': 115031,\n",
              " 'какой-то': 44688,\n",
              " 'карикатура': 45574,\n",
              " 'страшно': 119221,\n",
              " 'подумать': 90299,\n",
              " 'встретить': 19551,\n",
              " 'указанный': 128304,\n",
              " 'период': 86145,\n",
              " 'путь': 100913,\n",
              " 'разумный': 102846,\n",
              " 'взрослый': 15892,\n",
              " 'гетеросексуальный': 23113,\n",
              " 'белый': 8581,\n",
              " 'мужчина': 65908,\n",
              " 'респектабельный': 105458,\n",
              " 'профессия': 99671,\n",
              " 'найти': 68006,\n",
              " 'хоть': 136036,\n",
              " 'повод': 88842,\n",
              " 'побег': 88560,\n",
              " 'свой': 110410,\n",
              " 'скорлупа': 113197,\n",
              " 'ну': 75686,\n",
              " 'итог': 43945,\n",
              " 'описать': 79541,\n",
              " 'стать': 118258,\n",
              " 'слоганом': 114029,\n",
              " 'основной': 80501,\n",
              " 'мысль': 66646,\n",
              " 'кинокартина': 47879,\n",
              " 'ведь': 14736,\n",
              " 'чем': 138197,\n",
              " 'приоткрывать': 97088,\n",
              " 'этот': 144038,\n",
              " 'идти': 41068,\n",
              " 'мир': 63624,\n",
              " 'намерение': 68312,\n",
              " 'тем': 123116,\n",
              " 'сильный': 112091,\n",
              " 'улучшать': 128524,\n",
              " 'собственный': 115174,\n",
              " 'из': 41115,\n",
              " 'плюс': 87916,\n",
              " 'хотеть': 136022,\n",
              " 'умалять': 128636,\n",
              " 'заслуга': 38544,\n",
              " 'хелена': 134820,\n",
              " 'хант': 134283,\n",
              " 'особенно': 80519,\n",
              " 'удаться': 127718,\n",
              " 'сцена': 121026,\n",
              " 'письмо': 87260,\n",
              " 'благодарность': 9989,\n",
              " 'страница': 119113,\n",
              " 'выдавать': 20163,\n",
              " 'невероятный': 70164,\n",
              " 'перформанс': 86432,\n",
              " 'вновь': 17169,\n",
              " 'подтверждать': 90258,\n",
              " 'звание': 39328,\n",
              " 'один': 78044,\n",
              " 'актёр': 2884,\n",
              " 'современность': 115359,\n",
              " 'вызывать': 20318,\n",
              " 'сочувствие': 116672,\n",
              " 'смех': 114432,\n",
              " 'раздражение': 102248,\n",
              " 'отвращение': 81038,\n",
              " 'снова': 114923,\n",
              " 'круг': 53589,\n",
              " 'одновременно': 78152,\n",
              " 'зритель': 40479,\n",
              " 'нет': 73933,\n",
              " 'необходимость': 72239,\n",
              " 'экскурс': 142407,\n",
              " 'прошлое': 99897,\n",
              " 'выяснять': 21422,\n",
              " 'именно': 42041,\n",
              " 'благодаря': 9994,\n",
              " 'игра': 40799,\n",
              " 'выглядеть': 20111,\n",
              " 'рельефно': 105215,\n",
              " 'полноценно': 91419,\n",
              " 'время': 19052,\n",
              " 'странный': 119139,\n",
              " 'нелогичный': 71838,\n",
              " 'поступок': 93963,\n",
              " 'казаться': 44499,\n",
              " 'достоверный': 32437,\n",
              " 'выбрать': 20027,\n",
              " 'формат': 132908,\n",
              " 'комедия': 50357,\n",
              " 'выходить': 21284,\n",
              " 'убить': 127273,\n",
              " 'два': 27311,\n",
              " 'зайцев': 37181,\n",
              " 'посмеяться': 93571,\n",
              " 'изобразить': 41591,\n",
              " 'серьёзный': 111671,\n",
              " 'проблема': 97873,\n",
              " 'лёгкое': 58399,\n",
              " 'комический': 50513,\n",
              " 'вид': 15983,\n",
              " 'при': 96087,\n",
              " 'значение': 40190,\n",
              " 'сам': 108548,\n",
              " 'год': 24200,\n",
              " 'просмотр': 99179,\n",
              " 'фильм-номинант': 131975,\n",
              " 'сказываться': 112741,\n",
              " 'кино': 47334,\n",
              " 'тема': 123122,\n",
              " 'понемногу': 92480,\n",
              " 'начинать': 69734,\n",
              " 'вязнуть': 21512,\n",
              " 'зуб': 40535,\n",
              " 'минус': 63577,\n",
              " 'создавать': 115507,\n",
              " 'замечательный': 37727,\n",
              " 'весёлый': 15437,\n",
              " 'настроение': 69277,\n",
              " 'послевкусие': 93477,\n",
              " 'почему-то': 94548,\n",
              " 'приятный': 97806,\n",
              " 'ли': 56432,\n",
              " 'за': 36172,\n",
              " 'внезапно': 17090,\n",
              " 'вспоминать': 19477,\n",
              " 'оно': 79349,\n",
              " 'конец': 50891,\n",
              " 'неясно': 74533,\n",
              " 'побороть': 88635,\n",
              " 'болезнь': 11010,\n",
              " 'психологический': 100474,\n",
              " 'трабла': 124831,\n",
              " 'или': 41903,\n",
              " 'временной': 19046,\n",
              " 'ремиссия': 105288,\n",
              " 'последовать': 93505,\n",
              " 'неизбежный': 71447,\n",
              " 'обострение': 77000,\n",
              " 'героиня': 22781,\n",
              " 'выбор': 20004,\n",
              " 'следствие': 113766,\n",
              " 'чувство': 139126,\n",
              " 'вперемешку': 18748,\n",
              " 'мамин': 59925,\n",
              " 'воспитание': 18428,\n",
              " 'содержимый': 115443,\n",
              " 'обязательный': 77669,\n",
              " 'пункт': 100768,\n",
              " 'о': 76066,\n",
              " 'надо': 67633,\n",
              " 'брать': 11838,\n",
              " 'кто': 53923,\n",
              " 'есть': 34820,\n",
              " 'закончиться': 37390,\n",
              " 'ситуация': 112552,\n",
              " 'полный': 91427,\n",
              " 'опустошение': 79797,\n",
              " 'материальный': 60982,\n",
              " 'моральный': 65096,\n",
              " 'лишь': 57064,\n",
              " 'вопрос': 18212,\n",
              " 'без': 7761,\n",
              " 'ответ': 80957,\n",
              " 'знать': 40181,\n",
              " 'правда': 94806,\n",
              " 'стоить': 118798,\n",
              " 'заглядывать': 36695,\n",
              " 'титр': 123926,\n",
              " 'цитата': 137367,\n",
              " 'никогда': 74749,\n",
              " 'отрывать': 81956,\n",
              " 'кругом': 53607,\n",
              " 'объять': 77574,\n",
              " 'пламя': 87460,\n",
              " 'услышать': 129625,\n",
              " 'стук': 119600,\n",
              " 'падать': 83032,\n",
              " 'тело': 123093,\n",
              " 'через': 138268,\n",
              " 'неделя': 70651,\n",
              " 'почувствовать': 94616,\n",
              " 'запах': 38046,\n",
              " 'разлагаться': 102345,\n",
              " 'мясо': 67064,\n",
              " 'тогда': 124104,\n",
              " 'приходить': 97613,\n",
              " 'когда': 49549,\n",
              " 'заслать': 38532,\n",
              " 'ресторан': 105485,\n",
              " 'показаться': 90776,\n",
              " 'заговорить': 36719,\n",
              " 'потому': 94149,\n",
              " 'плохо': 87838,\n",
              " 'почему': 94542,\n",
              " 'нормальный': 75460,\n",
              " 'парень': 83686,\n",
              " 'закидон': 37264,\n",
              " 'милый': 63291,\n",
              " 'бывать': 13208,\n",
              " 'теперь': 123267,\n",
              " 'мой': 64542,\n",
              " 'любимый': 58034,\n",
              " 'жанр': 35010,\n",
              " 'где': 22265,\n",
              " 'преимущество': 95623,\n",
              " 'отдавать': 81098,\n",
              " 'свойственный': 110422,\n",
              " 'гангстерский': 21923,\n",
              " 'драка': 32701,\n",
              " 'перестрелка': 85948,\n",
              " 'том': 124319,\n",
              " 'далее': 26913,\n",
              " 'картина': 45788,\n",
              " 'построить': 93923,\n",
              " 'мастерский': 60891,\n",
              " 'диалог': 30431,\n",
              " 'погружать': 89101,\n",
              " 'история': 43796,\n",
              " 'начало': 69678,\n",
              " 'становиться': 117928,\n",
              " 'ни': 74547,\n",
              " 'чуть': 139419,\n",
              " 'скучно': 113539,\n",
              " 'депп': 28860,\n",
              " 'конечно': 50896,\n",
              " 'молодой': 64653,\n",
              " 'впечатление': 18762,\n",
              " 'произвести': 98446,\n",
              " 'чувствоваться': 139137,\n",
              " 'ныне': 75855,\n",
              " 'харизма': 134415,\n",
              " 'аль': 3375,\n",
              " 'пачиный': 84411,\n",
              " 'великолепный': 14889,\n",
              " 'создать': 115536,\n",
              " 'кадр': 44419,\n",
              " 'посмеиваться': 93561,\n",
              " 'над': 67529,\n",
              " 'комичность': 50527,\n",
              " 'левша': 55701,\n",
              " 'главный': 23679,\n",
              " 'под': 89130,\n",
              " 'настолько': 69225,\n",
              " 'проникаться': 98813,\n",
              " 'сочувствовать': 116673,\n",
              " 'что-то': 139058,\n",
              " 'бенджамин': 8645,\n",
              " 'олицетворение': 79108,\n",
              " 'обычный': 77634,\n",
              " 'постоянный': 93886,\n",
              " 'стремление': 119301,\n",
              " 'слава': 113614,\n",
              " 'успех': 129673,\n",
              " 'постоянство': 93887,\n",
              " 'неудача': 74073,\n",
              " 'смирение': 114501,\n",
              " 'потеря': 94093,\n",
              " 'близкий': 10245,\n",
              " 'приедаться': 96483,\n",
              " 'монотонный': 64909,\n",
              " 'пейзаж': 84545,\n",
              " 'расплескаться': 103450,\n",
              " 'пятно': 101365,\n",
              " 'краска': 52781,\n",
              " 'бел': 8409,\n",
              " 'холст': 135787,\n",
              " 'вносить': 17171,\n",
              " 'детальный': 29190,\n",
              " 'кровавый': 53375,\n",
              " 'бойня': 10898,\n",
              " 'вписываться': 18800,\n",
              " 'общий': 77488,\n",
              " 'бодрить': 10740,\n",
              " 'бдительность': 7587,\n",
              " 'дать': 27244,\n",
              " 'показатель': 90765,\n",
              " 'цена': 137078,\n",
              " 'маленький': 59361,\n",
              " 'государство': 25184,\n",
              " 'кусок': 54605,\n",
              " 'железо': 35189,\n",
              " 'скрытый': 113420,\n",
              " 'шикарный': 140439,\n",
              " 'строчка': 119451,\n",
              " 'сценарий': 121056,\n",
              " 'ангел': 3968,\n",
              " 'разный': 102629,\n",
              " 'обличие': 76652,\n",
              " 'действовать': 28340,\n",
              " 'хитро': 135281,\n",
              " 'лента': 56053,\n",
              " 'хранитель': 136159,\n",
              " 'душа': 33693,\n",
              " 'людская': 58217,\n",
              " 'раздавать': 102164,\n",
              " 'тумак': 126349,\n",
              " 'посредством': 93658,\n",
              " 'удар': 127695,\n",
              " 'точный': 124790,\n",
              " 'больший': 11118,\n",
              " 'часть': 137703,\n",
              " 'хотя': 136040,\n",
              " 'случается': 114162,\n",
              " 'вовсе': 17297,\n",
              " 'херувим': 134991,\n",
              " 'крыло': 53739,\n",
              " 'дерьмо': 29032,\n",
              " 'жёлчь': 36143,\n",
              " 'пропитать': 98920,\n",
              " 'каждый': 44456,\n",
              " 'слово': 113981,\n",
              " 'немолодой': 71979,\n",
              " 'половина': 91432,\n",
              " 'кинолента': 47938,\n",
              " 'вдобавок': 14604,\n",
              " 'приправить': 97170,\n",
              " 'сумасшествие': 120048,\n",
              " 'мыло': 66608,\n",
              " 'использовать': 43520,\n",
              " 'закрыть': 37476,\n",
              " 'открыть': 81440,\n",
              " 'дверной': 27375,\n",
              " 'много': 64093,\n",
              " 'трещина': 125542,\n",
              " 'брусчатка': 12362,\n",
              " 'асфальт': 5819,\n",
              " 'наступить': 69298,\n",
              " 'однако': 78121,\n",
              " 'острый': 80781,\n",
              " 'брезгливость': 11912,\n",
              " 'число': 138819,\n",
              " 'общение': 77436,\n",
              " 'успешный': 129680,\n",
              " 'книга': 49326,\n",
              " 'читатель': 138872,\n",
              " 'находить': 69598,\n",
              " 'ключик': 49272,\n",
              " 'секрет': 110903,\n",
              " 'человеческий': 138155,\n",
              " 'характер': 134330,\n",
              " 'автор': 1937,\n",
              " 'роман': 106895,\n",
              " 'общаться': 77406,\n",
              " 'совсем': 115368,\n",
              " 'предпочитать': 95377,\n",
              " 'устраивать': 129753,\n",
              " 'ежедневный': 34550,\n",
              " 'унижение': 128890,\n",
              " 'художник': 136389,\n",
              " 'саймон': 108391,\n",
              " 'гречь': 25649,\n",
              " 'киннир': 47333,\n",
              " 'официантка': 82560,\n",
              " 'кэрол': 54903,\n",
              " 'закусочный': 37503,\n",
              " 'прочитать': 99838,\n",
              " 'написать': 68539,\n",
              " 'кружение': 53619,\n",
              " 'слышать': 114197,\n",
              " 'кто-то': 53941,\n",
              " 'трезвомыслящий': 125265,\n",
              " 'говорить': 24156,\n",
              " 'друг': 33041,\n",
              " 'смысл': 114727,\n",
              " 'видеть': 16160,\n",
              " 'продолжение': 98246,\n",
              " 'выздоровление': 20307,\n",
              " 'приносить': 96970,\n",
              " 'результат': 104980,\n",
              " 'незримый': 71425,\n",
              " 'витать': 16664,\n",
              " 'между': 61799,\n",
              " 'процесс': 99813,\n",
              " 'менять': 62257,\n",
              " 'место': 62501,\n",
              " 'дислокация': 30990,\n",
              " 'социопат': 116602,\n",
              " 'раздражать': 102243,\n",
              " 'поработать': 93014,\n",
              " 'воскрешать': 18407,\n",
              " 'осознанный': 80569,\n",
              " 'спаситель': 116796,\n",
              " 'озлобить': 78523,\n",
              " 'присутствовать': 97402,\n",
              " 'лирический': 56806,\n",
              " 'любовный': 58100,\n",
              " 'пёсик': 101423,\n",
              " 'сколь': 113108,\n",
              " 'уродливый': 129454,\n",
              " 'столь': 118875,\n",
              " 'кличка': 49096,\n",
              " 'верделла': 15113,\n",
              " 'играть': 40823,\n",
              " 'шесть': 140338,\n",
              " 'порода': 93174,\n",
              " 'брюссельский': 12496,\n",
              " 'гриффон': 25805,\n",
              " 'тварь': 122720,\n",
              " 'волновать': 17926,\n",
              " 'нюнислюни': 75997,\n",
              " 'сегодняшний': 110796,\n",
              " 'уникальный': 128908,\n",
              " 'немой': 71976,\n",
              " 'лживый': 56430,\n",
              " 'толлерантность': 124228,\n",
              " 'превращать': 95128,\n",
              " 'безвкусно-бесцветный': 7830,\n",
              " 'гель': 22430,\n",
              " 'стоять': 119025,\n",
              " 'перл': 86177,\n",
              " 'восторженный': 18568,\n",
              " 'читательница': 138876,\n",
              " 'спрашивать': 117423,\n",
              " 'мэлвин': 66816,\n",
              " 'проникнуть': 98827,\n",
              " 'душить': 33759,\n",
              " 'взять': 15945,\n",
              " 'лишить': 57056,\n",
              " 'разум': 102830,\n",
              " 'долг': 31798,\n",
              " 'знакомство': 40143,\n",
              " 'поездка': 90445,\n",
              " 'представлять': 95472,\n",
              " 'официантка-саймон': 82561,\n",
              " 'педик': 84517,\n",
              " 'резкий': 104953,\n",
              " 'пассаж': 84045,\n",
              " 'фон': 132819,\n",
              " 'размеренность': 102447,\n",
              " 'кстати': 53912,\n",
              " 'хвалёный': 134668,\n",
              " 'гораздо': 24735,\n",
              " 'интересный': 42731,\n",
              " 'смотреть': 114631,\n",
              " 'коль': 50177,\n",
              " 'воображение': 18141,\n",
              " 'очень': 82797,\n",
              " 'лично': 57019,\n",
              " 'из-за': 41118,\n",
              " 'участие': 130144,\n",
              " 'лёгкий': 58395,\n",
              " 'ненавязчивый': 72047,\n",
              " 'романтический': 106974,\n",
              " 'злой': 40038,\n",
              " 'страшный': 119232,\n",
              " 'серый': 111655,\n",
              " 'волк': 17889,\n",
              " 'влюбляться': 16999,\n",
              " 'простой': 99300,\n",
              " 'открывать': 81421,\n",
              " 'нежный': 71192,\n",
              " 'оказываться': 78606,\n",
              " 'безумно': 8223,\n",
              " 'наивный': 67899,\n",
              " 'портить': 93243,\n",
              " 'целое': 137034,\n",
              " 'оставлять': 80607,\n",
              " 'характерный': 134351,\n",
              " 'весьма': 15431,\n",
              " 'карикатурный': 45587,\n",
              " 'прямо': 100031,\n",
              " 'скажем': 112634,\n",
              " 'маникально-депрессивный': 60066,\n",
              " 'синдром': 112274,\n",
              " 'всё-таки': 19634,\n",
              " 'сварливый': 109711,\n",
              " 'дядька': 34213,\n",
              " 'чей': 137801,\n",
              " 'причуда': 97696,\n",
              " 'улыбка': 128534,\n",
              " 'довольно': 31474,\n",
              " 'требовать': 125209,\n",
              " 'контекст': 51141,\n",
              " 'скорый': 113254,\n",
              " 'желание': 35149,\n",
              " 'помочь': 92349,\n",
              " 'больной': 11096,\n",
              " 'напротив': 68664,\n",
              " 'понаблюдать': 92429,\n",
              " 'выкинуть': 20380,\n",
              " 'учудить': 130259,\n",
              " 'таракан': 122416,\n",
              " 'голов': 24399,\n",
              " 'присущий': 97408,\n",
              " 'иной': 42504,\n",
              " 'степень': 118468,\n",
              " 'наверное': 67283,\n",
              " 'заключаться': 37300,\n",
              " 'некий': 71660,\n",
              " 'стереотипность': 118538,\n",
              " 'обязательно': 77667,\n",
              " 'одинокий': 78084,\n",
              " 'ребёнок': 104461,\n",
              " 'гомосексуалист': 24589,\n",
              " 'маленькая': 59359,\n",
              " 'собираться': 115106,\n",
              " 'счастливый': 121155,\n",
              " 'увы': 127485,\n",
              " 'удивление': 127776,\n",
              " 'вызвать': 20292,\n",
              " 'роль': 106869,\n",
              " 'бедный': 7697,\n",
              " 'женщина-официантка': 35417,\n",
              " 'согласный': 115391,\n",
              " 'здорово': 39546,\n",
              " 'сверхъестественный': 110101,\n",
              " 'суперпрофессиональный': 120557,\n",
              " 'обычно': 77630,\n",
              " 'должный': 31861,\n",
              " 'давать': 26757,\n",
              " 'награда': 67492,\n",
              " 'её': 34885,\n",
              " 'амплуа': 3799,\n",
              " 'представать': 95453,\n",
              " 'последний': 93490,\n",
              " 'двадцать': 27348,\n",
              " 'периодически': 86151,\n",
              " 'подкручивать': 89584,\n",
              " 'винтик': 16524,\n",
              " 'более': 10987,\n",
              " 'эгоистический': 141852,\n",
              " 'менее': 62170,\n",
              " 'зависимость': 36473,\n",
              " 'несмотря': 73679,\n",
              " 'вышесказанный': 21380,\n",
              " 'можно': 64481,\n",
              " 'посмотреть': 93583,\n",
              " 'семья': 111235,\n",
              " 'вечером': 15504,\n",
              " 'экран': 142274,\n",
              " 'телевизор': 122950,\n",
              " 'честной': 138508,\n",
              " 'хотеться': 136024,\n",
              " 'очевидный': 82780,\n",
              " 'развитие': 101979,\n",
              " 'сюжет': 121584,\n",
              " 'завязка': 36618,\n",
              " 'удалый': 127687,\n",
              " 'популярный': 92974,\n",
              " 'мизантроп': 62925,\n",
              " 'поздне-среднее': 90584,\n",
              " 'единственный': 34516,\n",
              " 'радость': 101756,\n",
              " 'работа': 101477,\n",
              " 'выверить': 20062,\n",
              " 'мелкий': 61970,\n",
              " 'деталь': 29180,\n",
              " 'рутина': 107707,\n",
              " 'дом': 31924,\n",
              " 'что-нибудь': 139053,\n",
              " 'купить': 54415,\n",
              " 'поесть': 90454,\n",
              " 'кафе': 46243,\n",
              " 'строго': 119404,\n",
              " 'отвести': 80953,\n",
              " 'помощь': 92374,\n",
              " 'прибор': 96151,\n",
              " 'любить': 58046,\n",
              " 'издалёка': 41345,\n",
              " 'личный': 57039,\n",
              " 'невыносимый': 70408,\n",
              " 'принцип': 97040,\n",
              " 'способный': 117373,\n",
              " 'разговаривать': 102110,\n",
              " 'минута': 63592,\n",
              " 'коннель': 50962,\n",
              " 'прямая': 100029,\n",
              " 'грубость': 25975,\n",
              " 'нея': 74524,\n",
              " 'куча': 54670,\n",
              " 'поведение': 88714,\n",
              " 'экстравагантный': 142536,\n",
              " 'относиться': 81645,\n",
              " 'определённый': 79701,\n",
              " 'понимание': 92510,\n",
              " 'суждено': 119965,\n",
              " 'мирно': 63671,\n",
              " 'тихо': 123956,\n",
              " 'помереть': 92243,\n",
              " 'упорядочить': 129228,\n",
              " 'мирок': 63694,\n",
              " 'этаж': 143952,\n",
              " 'художник-гомосексуалист': 136395,\n",
              " 'попадать': 92741,\n",
              " 'больница': 11087,\n",
              " 'спихивать': 117135,\n",
              " 'уход': 130108,\n",
              " 'туповатый': 126427,\n",
              " 'мила': 63094,\n",
              " 'возникать': 17689,\n",
              " 'бросить': 12288,\n",
              " 'главное': 23654,\n",
              " 'приходиться': 97616,\n",
              " 'выйти': 20351,\n",
              " 'зона': 40364,\n",
              " 'комфорт': 50782,\n",
              " 'защитить': 39272,\n",
              " 'депрессивно-однообразный': 28885,\n",
              " 'образ': 77033,\n",
              " 'крайне': 52579,\n",
              " 'циничный': 137321,\n",
              " 'депрессивный': 28891,\n",
              " 'мужик': 65856,\n",
              " 'психический': 100411,\n",
              " 'нестабильность': 73824,\n",
              " 'практически': 95003,\n",
              " 'пытка': 101093,\n",
              " 'интересно': 42724,\n",
              " 'наблюдать': 67195,\n",
              " 'какой': 44674,\n",
              " 'наслаждение': 69086,\n",
              " 'работать': 101489,\n",
              " 'отгораживаться': 81077,\n",
              " 'оскорбление': 80376,\n",
              " 'теряться': 123475,\n",
              " 'сталкиваться': 117865,\n",
              " 'несколько': 73597,\n",
              " 'исполнение': 43487,\n",
              " 'понравиться': 92547,\n",
              " 'застрять': 38691,\n",
              " 'вместо': 17036,\n",
              " 'младенчество': 64015,\n",
              " 'сын-аллергик': 121274,\n",
              " 'отпугивать': 81819,\n",
              " 'худой': 136436,\n",
              " 'мелвиновский': 61950,\n",
              " 'цинизм': 137301,\n",
              " 'отзывчивый': 81304,\n",
              " 'девушка': 27909,\n",
              " 'оказаться': 78601,\n",
              " 'заложница': 37591,\n",
              " 'обстоятельство': 77270,\n",
              " 'основное': 80499,\n",
              " 'вращаться': 19021,\n",
              " 'вокруг': 17847,\n",
              " 'более-менее': 10990,\n",
              " 'приличный': 96810,\n",
              " 'балансировать': 6733,\n",
              " 'грань': 25473,\n",
              " 'партнёр': 83952,\n",
              " 'фрэнк': 133501,\n",
              " 'достаточно': 32414,\n",
              " 'мера': 62259,\n",
              " 'облако': 76566,\n",
              " 'искусство': 43372,\n",
              " 'слюнтяй': 114236,\n",
              " 'превращаться': 95129,\n",
              " 'темпераментный': 123169,\n",
              " 'самодостаточный': 108699,\n",
              " 'мебель': 61400,\n",
              " 'пара': 83541,\n",
              " 'смешной': 114472,\n",
              " 'смотреться': 114641,\n",
              " 'взгляд': 15766,\n",
              " 'заслуженно': 38550,\n",
              " 'крепкий': 52991,\n",
              " 'местами': 62488,\n",
              " 'проявляться': 99942,\n",
              " 'юмор': 144333,\n",
              " 'неплохой': 72674,\n",
              " 'уровень': 129433,\n",
              " 'выводить': 20085,\n",
              " 'похожий': 94475,\n",
              " 'здесь': 39524,\n",
              " 'баланс': 6730,\n",
              " 'мрачноватый': 65665,\n",
              " 'драма': 32745,\n",
              " 'экспозиция': 142469,\n",
              " 'выдержать': 20208,\n",
              " 'превосходно': 95114,\n",
              " 'подобрать': 89772,\n",
              " 'саундтрек': 109516,\n",
              " 'снятой': 114991,\n",
              " 'красиво': 52762,\n",
              " 'прекрасно': 95653,\n",
              " 'попытка': 92998,\n",
              " 'показать': 90771,\n",
              " 'отношение': 81647,\n",
              " 'непростой': 73226,\n",
              " 'довести': 31452,\n",
              " 'очень-то': 82804,\n",
              " 'линия': 56717,\n",
              " 'скорее': 113189,\n",
              " 'продукт': 98269,\n",
              " 'отдельность': 81131,\n",
              " 'костяк': 52211,\n",
              " 'вывод': 20082,\n",
              " 'отличный': 81512,\n",
              " 'всего': 19203,\n",
              " 'блестящий': 10217,\n",
              " 'сложный': 114060,\n",
              " 'вынужденный': 20599,\n",
              " 'доброта': 31373,\n",
              " 'сопля': 116076,\n",
              " 'здоровый': 39552,\n",
              " 'доля': 31923,\n",
              " 'мрачный': 65667,\n",
              " 'шедевр': 140071,\n",
              " 'нравиться': 75643,\n",
              " 'динамический': 30777,\n",
              " 'возможность': 17653,\n",
              " 'отдохнуть': 81141,\n",
              " 'отвлечься': 81002,\n",
              " 'полезный': 91099,\n",
              " 'информация': 42983,\n",
              " 'оптимистический': 79761,\n",
              " 'название': 67796,\n",
              " 'завоевать': 36533,\n",
              " 'множество': 64330,\n",
              " 'престижный': 95947,\n",
              " 'состав': 116348,\n",
              " 'профессионально': 99667,\n",
              " 'исполнить': 43507,\n",
              " 'яркий': 144902,\n",
              " 'звезда': 39335,\n",
              " 'голливуд': 24360,\n",
              " 'справиться': 117406,\n",
              " 'люба': 57986,\n",
              " 'связанный': 110476,\n",
              " 'называться': 67851,\n",
              " 'иронический': 43154,\n",
              " 'прелесть': 95681,\n",
              " 'решение': 105742,\n",
              " 'тяжёлый': 126956,\n",
              " 'преподноситься': 95824,\n",
              " 'забавный': 36211,\n",
              " 'мастерски': 60889,\n",
              " 'обыграть': 77598,\n",
              " 'эксцентричный': 142600,\n",
              " 'ненавидеть': 72029,\n",
              " 'презирать': 95607,\n",
              " 'заразный': 38357,\n",
              " 'микроб': 63018,\n",
              " 'постепенно': 93804,\n",
              " 'изменяться': 41480,\n",
              " 'открытый': 81438,\n",
              " 'захотеться': 39080,\n",
              " 'измениться': 41467,\n",
              " 'достоинство': 32447,\n",
              " 'шаблонный': 139581,\n",
              " 'предсказуемый': 95443,\n",
              " 'поворот': 88869,\n",
              " 'событие': 115184,\n",
              " 'неожиданный': 72349,\n",
              " 'осознание': 80566,\n",
              " 'изменить': 41465,\n",
              " 'сторона': 118967,\n",
              " 'ваш': 14460,\n",
              " 'пополнить': 92869,\n",
              " 'список': 117122,\n",
              " 'великий': 14857,\n",
              " 'итак': 43901,\n",
              " 'увлекательный': 127456,\n",
              " 'провести': 97964,\n",
              " 'весело': 15328,\n",
              " 'отдыхать': 81153,\n",
              " 'удовольствие': 127833,\n",
              " 'польза': 92146,\n",
              " 'сейчас': 110884,\n",
              " 'часто': 137691,\n",
              " 'увидеть': 127431,\n",
              " 'подобный': 89764,\n",
              " 'род': 106445,\n",
              " 'ранний': 103093,\n",
              " 'элемент': 142934,\n",
              " 'про': 97823,\n",
              " 'плохой': 87849,\n",
              " 'нужно': 75778,\n",
              " 'разряд': 102805,\n",
              " 'пересматривать': 85881,\n",
              " 'отдельно': 81128,\n",
              " 'выделить': 20197,\n",
              " 'поистине': 90721,\n",
              " 'любой': 58132,\n",
              " 'действие': 28322,\n",
              " 'восхищение': 18620,\n",
              " 'разумеется': 102835,\n",
              " 'музыкальный': 66032,\n",
              " 'сопровождение': 116122,\n",
              " 'ханс': 134276,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vog_PtAPemrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to get index and feature\n",
        "index_to_word = {\n",
        "    ind: word\n",
        "    for (word, ind)\n",
        "    in lemmas_vectorizer.vocabulary_.items()\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpIt8NphOP1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78b1402e-7edd-41a9-8e13-ee6c8dc59125"
      },
      "source": [
        "clf.coef_.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 145142)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ml-yEPkfGTE",
        "colab_type": "code",
        "outputId": "e12d3373-4736-481c-8133-62e210745e0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf.classes_"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1,  0,  1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7go0ZPSfNcj",
        "colab_type": "code",
        "outputId": "949fd0be-e094-4e00-a83d-f4e53e756169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Класс отрицательных отзывов - первые 20 коэффициентов\n",
        "top_features = sorted(enumerate(clf.coef_[0]), key=lambda pair: pair[1], reverse=True)[:20]\n",
        "for index, value in top_features:\n",
        "  print(index_to_word[index], index)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "скучный 113551\n",
            "зачем 39147\n",
            "ничто 75025\n",
            "единственный 34516\n",
            "разочарование 102698\n",
            "никакой 74704\n",
            "нет 73933\n",
            "видимо 16173\n",
            "вообще 18155\n",
            "откровенно 81401\n",
            "скучно 113539\n",
            "пустой 100839\n",
            "разочаровать 102707\n",
            "вместо 17036\n",
            "бред 11880\n",
            "унылый 128971\n",
            "глупый 23956\n",
            "абсолютно 1544\n",
            "ужасный 127935\n",
            "пытаться 101086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwdkebzAe3ix",
        "colab_type": "code",
        "outputId": "04cdd930-2427-4b3b-daa5-0b7c5d9735e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Класс отрицательных отзывов - последние 20 коэффициентов\n",
        "top_features = sorted(enumerate(clf.coef_[0]), key=lambda pair: pair[1])[:20]\n",
        "for index, value in top_features:\n",
        "  print(index_to_word[index])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "каждый\n",
            "жизнь\n",
            "отличный\n",
            "очень\n",
            "отлично\n",
            "он\n",
            "немного\n",
            "замечательный\n",
            "потрясать\n",
            "приятно\n",
            "роль\n",
            "некоторый\n",
            "приятный\n",
            "целое\n",
            "особенно\n",
            "несмотря\n",
            "свой\n",
            "стоить\n",
            "прекрасный\n",
            "место\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlIanHfvfLF-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "96e6841a-124f-4c0f-8fc6-1f3e2df5caba"
      },
      "source": [
        "# Класс нейтральных отзывов - первые 20 коэффициентов\n",
        "top_features = sorted(enumerate(clf.coef_[1]), key=lambda pair: pair[1], reverse=True)[:20]\n",
        "for index, value in top_features:\n",
        "  print(index_to_word[index])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "нейтральный\n",
            "неплохой\n",
            "но\n",
            "как-то\n",
            "целое\n",
            "сторона\n",
            "увы\n",
            "претензия\n",
            "слишком\n",
            "всё-таки\n",
            "чего-то\n",
            "хватать\n",
            "ностальгия\n",
            "слабый\n",
            "ожидать\n",
            "разок\n",
            "оценивать\n",
            "поэтому\n",
            "вот\n",
            "концовка\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5AJyN9BO-H7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "aa0a58f2-9d73-478f-b0ff-6316b1e3d442"
      },
      "source": [
        "# Класс нейтральных отзывов - последние 20 коэффициентов\n",
        "top_features = sorted(enumerate(clf.coef_[1]), key=lambda pair: pair[1])[:20]\n",
        "for index, value in top_features:\n",
        "  print(index_to_word[index])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "из\n",
            "шедевр\n",
            "это\n",
            "рекомендовать\n",
            "обычно\n",
            "юмор\n",
            "приключение\n",
            "один\n",
            "абсолютно\n",
            "небо\n",
            "написать\n",
            "который\n",
            "настолько\n",
            "достойный\n",
            "важный\n",
            "минута\n",
            "звучать\n",
            "безумный\n",
            "фрэнк\n",
            "ещё\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeJeCd4YPJjO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "98e9b25c-2922-49fd-d9b4-5b3a34f87ab3"
      },
      "source": [
        "# Класс положительных отзывов - первые 20 коэффициентов\n",
        "top_features = sorted(enumerate(clf.coef_[2]), key=lambda pair: pair[1], reverse=True)[:20]\n",
        "for index, value in top_features:\n",
        "  print(index_to_word[index])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "каждый\n",
            "отличный\n",
            "очень\n",
            "прекрасный\n",
            "великолепный\n",
            "отлично\n",
            "потрясать\n",
            "один\n",
            "замечательный\n",
            "настоящий\n",
            "являться\n",
            "свой\n",
            "однозначно\n",
            "шикарный\n",
            "рекомендовать\n",
            "идеальный\n",
            "он\n",
            "дыхание\n",
            "прекрасно\n",
            "юмор\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Poc1Ifp7PWO9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "5a60d622-ce8e-414f-8c84-e7dadfb888d8"
      },
      "source": [
        "# Класс положительных отзывов - последние 20 коэффициентов\n",
        "top_features = sorted(enumerate(clf.coef_[2]), key=lambda pair: pair[1])[:20]\n",
        "for index, value in top_features:\n",
        "  print(index_to_word[index])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "скучный\n",
            "увы\n",
            "зачем\n",
            "ничто\n",
            "никакой\n",
            "скучно\n",
            "идея\n",
            "сожаление\n",
            "плохой\n",
            "видимо\n",
            "неплохой\n",
            "разочарование\n",
            "предсказуемый\n",
            "пустой\n",
            "не\n",
            "откровенно\n",
            "непонятно\n",
            "нейтральный\n",
            "вообще\n",
            "слишком\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhPe-7jKWw7m",
        "colab_type": "text"
      },
      "source": [
        "### confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_7jjaaJWtdt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "df7c8d58-4e82-4906-cb42-c0108231f468"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqdqaLoRWu53",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "84fbbcc8-de6a-43c8-df6c-02dfbdd2a89a"
      },
      "source": [
        "categories = ['Отрицательные', 'Нейтральные', 'Положительные']\n",
        "sns.heatmap(data=confusion_matrix(y_test, clf.predict(X_test)), annot=True, fmt=\"d\", cbar=False, xticklabels=categories, yticklabels=categories)\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcgAAAEWCAYAAADilQe1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkGZmZhkckGZmZhn+H5xSxc3TAwr/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvL5lKmodXAL",
        "colab_type": "text"
      },
      "source": [
        "**Результаты:**\n",
        "  \n",
        "\n",
        "1.   Получены хорошие результаты классификации положительных отзывов.\n",
        "2.   Большинство по факту нейтральных отзывов классификатор отнес к положительным. Глядя на топ-20 признаков из нейтральных отзывов, это неудивительно, но не понятно, как можно это улучшить. \n",
        "3.  Большая доля отрицательных отзывов была классифицирована как положительные, при том, что топ-признаки выглядят довольно однозначно. По всей видимости, в большой части отрицательных отзывов таких однозначных признаков нет. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONg_-dLRmO5i",
        "colab_type": "text"
      },
      "source": [
        "## Попробуем еще классификаторы на лемматизированных токенах"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBqpQO3WmdGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1kvNvMQkohJ",
        "colab_type": "text"
      },
      "source": [
        "### дерево решений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Pr3Ck5SvCvb",
        "colab_type": "code",
        "outputId": "19259f0a-5a0a-44e1-bfbe-9ec1d059a928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "# дерево решений\n",
        "clf_tree = DecisionTreeClassifier()\n",
        "clf_tree.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dp8K7jyvRvD",
        "colab_type": "code",
        "outputId": "f25d831f-11b2-44ad-c197-49d12f8d2612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "print(classification_report(y_test, clf_tree.predict(X_test))) #"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.25      0.23      0.24      1117\n",
            "           0       0.19      0.18      0.18      1409\n",
            "           1       0.83      0.84      0.83      9100\n",
            "\n",
            "    accuracy                           0.70     11626\n",
            "   macro avg       0.42      0.42      0.42     11626\n",
            "weighted avg       0.69      0.70      0.70     11626\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4DYtE1hkr4U",
        "colab_type": "text"
      },
      "source": [
        "### случайный лес"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A8mJMMTwdCl",
        "colab_type": "code",
        "outputId": "f595305e-1a97-4908-adfc-2df5b9b79f72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "# случайный лес\n",
        "clf_forest = RandomForestClassifier()\n",
        "clf_forest.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyyGDcd4wkx7",
        "colab_type": "code",
        "outputId": "979ccac3-518b-4f73-949a-ea91e6455097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(classification_report(y_test, clf_forest.predict(X_test))) #"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00      1117\n",
            "           0       0.00      0.00      0.00      1409\n",
            "           1       0.78      1.00      0.88      9100\n",
            "\n",
            "    accuracy                           0.78     11626\n",
            "   macro avg       0.26      0.33      0.29     11626\n",
            "weighted avg       0.61      0.78      0.69     11626\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXOa5HfBk2gT",
        "colab_type": "text"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5iu7eoFx_x7",
        "colab_type": "code",
        "outputId": "dc4616ef-f56c-4356-a2bc-f0b0dba25b7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# наивный байес\n",
        "lemmas_nb_vect = CountVectorizer(tokenizer=preprocess_lemmatize)\n",
        "lemmas_nb_bow = lemmas_nb_vect.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(lemmas_nb_bow, df.label)\n",
        "clf_nb = MultinomialNB()\n",
        "clf_nb.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEtyGgQsyPfq",
        "colab_type": "code",
        "outputId": "b95e71fd-5bcb-443f-ae84-97cca65d3b16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "print(classification_report(y_test, clf_nb.predict(X_test))) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.62      0.45      0.52      1119\n",
            "           0       0.35      0.22      0.27      1393\n",
            "           1       0.87      0.95      0.90      9114\n",
            "\n",
            "    accuracy                           0.81     11626\n",
            "   macro avg       0.61      0.54      0.56     11626\n",
            "weighted avg       0.78      0.81      0.79     11626\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFE4eLH3i8-G",
        "colab_type": "text"
      },
      "source": [
        "## Grid Search - Подбор параметров логистической регресии\n",
        "\n",
        "Возьмем наилучший из полученных пока результатов (лемматизация + tfifd vectorizer + логистическая регрессия) и попробуем подобрать параметры регрессии"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR-l8_SAi6V-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upiFbEOKlMAz",
        "colab_type": "code",
        "outputId": "4551b9b9-c867-4d76-c71f-5c184152d713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clf = LogisticRegression()\n",
        "grid_values = {'penalty': ['l1', 'l2'],'C':[0.001,.009,0.01,.09,1,5,10,25]}\n",
        "grid_clf_acc = GridSearchCV(clf, param_grid = grid_values)\n",
        "grid_clf_acc.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.001, 0.009, 0.01, 0.09, 1, 5, 10, 25],\n",
              "                         'penalty': ['l1', 'l2']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVdn4DAApxL0",
        "colab_type": "code",
        "outputId": "ddb2755c-1ff6-41a9-9f69-03e341e9f5d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "clf_optimized = LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
        "                                          fit_intercept=True,\n",
        "                                          intercept_scaling=1, l1_ratio=None,\n",
        "                                          max_iter=100, multi_class='auto',\n",
        "                                          n_jobs=None, penalty='l2',\n",
        "                                          random_state=None, solver='lbfgs',\n",
        "                                          tol=0.0001, verbose=0,\n",
        "                                          warm_start=False)\n",
        "clf_optimized.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzVmyYVLqCvy",
        "colab_type": "code",
        "outputId": "6e48cdc8-3f73-464f-8d5d-ca491b9fb649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "print(classification_report(y_test, clf_optimized.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.74      0.49      0.59      1117\n",
            "           0       0.53      0.16      0.25      1409\n",
            "           1       0.86      0.99      0.92      9100\n",
            "\n",
            "    accuracy                           0.84     11626\n",
            "   macro avg       0.71      0.55      0.59     11626\n",
            "weighted avg       0.81      0.84      0.81     11626\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq8PMwxSc9GB",
        "colab_type": "text"
      },
      "source": [
        "**Вывод: по сравнению с настройками по умолчанию результат не улучшился**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QneIxQbijUh",
        "colab_type": "text"
      },
      "source": [
        "### Бонус\n",
        "(+2 балла к основному заданию; оценка за всё задание может быть выше 10)\n",
        "\n",
        "Придумайте ещё 2-3 осмысленных споцоба визуализации данных или результатов. Добавьте их ниже или в текст основного задания. и сошлитесь на них здесь."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zuERzL7ijUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}